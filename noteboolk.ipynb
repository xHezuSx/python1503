{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:40.348164900Z",
     "start_time": "2023-11-03T14:48:40.205036900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch                                    # importowanie po prostu torch\n",
    "import torchvision                              # dodanie biblioteki odpowiedzialnej za pobieranie danych obrazkowych\n",
    "import torch.nn as nn                           # dodanie biblioteki z odpowiednimi narzędziami do tworzenia modelu\n",
    "import torch.nn.functional as F                 # dodawanie funkcjonalności do modu w tym przypadku funkcję 'relu'\n",
    "import torchvision.transforms as transforms     # dodawanie funkcji dzięki której możemy zmienić dane na tensory \n",
    "import torch.optim as optim                     # dodawanie funkcji optymalizatora           \n",
    "from torch.utils.data import DataLoader         # dodawanie funkcji za pomocą której tworzymy treningowe BATCH'e dodatkowo możemy je posortować\n",
    "from torchvision.datasets import CIFAR10        # dodawanie funkcji dzięki której możemy pobrać dane treningowe i testowe CIFAR10 z 10 klasami objektów które są obrazkami \n",
    "\n",
    "import matplotlib.pyplot as plt                 # dodawanie biblioteki odpowiedzialnej za wyświetlanie wykresów/obrazków\n",
    "import numpy as np                              # numpy do liczb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\")                            # odpalanie operacji na karcie graficznej"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:40.349165600Z",
     "start_time": "2023-11-03T14:48:40.221049200Z"
    }
   },
   "id": "420e62bfc53064fd"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([                \n",
    "    transforms.ToTensor(),                      # ustawianie funkcji transformujacej w naszym przypadku obrazki 3x32x32 na tensor\n",
    "    transforms.Normalize((0.5,0.5,0.5),         # normalizacja kanałów argument 1: to średnia \n",
    "                         (0.5,0.5,0.5))])       # argument 2: to standardowe odchylenie                       \n",
    "\n",
    "BATCH_SIZE = 4                                  # liczba próbek 4 w jednym zestawie\n",
    "\n",
    "torch.manual_seed(42)                           # ustawianie aby losowe liczby były takie same\n",
    "\n",
    "train_data = CIFAR10(root='.', train=True, transform=transform, download=True)              # pobieranie danych trenignowych dla modelu z CIFAR10, przy okazji zamieniamy obrazki na tensory za pomocą wyżej zdefiniowanej funkcji transformacji\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   # zamienianie pojedynczych danych treningowych na zestawy w liczbie 'BATCH_SIZE' \n",
    "\n",
    "test_data = CIFAR10(root='.', train=False, transform=transform, download=True)              # pobieranie danych testowych dla modelu z CIFAR10, przy okazji zamieniamy obrazki na tensory za pomocą wyżej zdefiniowanej funkcji transformacji\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)    # zamienianie pojedynczych danych testowych na zestawy w liczbie 'BATCH_SIZE'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:41.931606500Z",
     "start_time": "2023-11-03T14:48:40.238065600Z"
    }
   },
   "id": "79bd6ee8260d3a91"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  # klasy w zestawach treningowych CIFAR10 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:41.959631900Z",
     "start_time": "2023-11-03T14:48:41.934608900Z"
    }
   },
   "id": "4e35858627f18fc1"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def imshow(img):                                        # funckja do wyświetlania obrazków\n",
    "    img = img / 2 + 0.5                                 # odwrócenie normalizacji aby obrazki wyglądały oryginalnie (mimo że nie wyglądają bo funkcja matplotlib coś zepsuła)\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))            # wyświetlanie i zamiana miejscami z [Channels, High, Width] na  [High, Width, Channels], ponieważ matplotlib tak wymaga\n",
    "    plt.show()                                          # wyświetlenie obrazka"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:41.996665700Z",
     "start_time": "2023-11-03T14:48:41.950624600Z"
    }
   },
   "id": "ba9827b616c6f4f1"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)                           # zamiana zbitku danych w iterowanlny objekt \n",
    "images, labels = next(dataiter)                         # wybranie 'następnego' elementu ze zbitku danych i rozdzielenie go na obrazki w postaci tensora oraz na typ klasy (nagłówek)\n",
    "print(images.shape, labels.shape)                       # wyświetlanie rozmiarów obrazków (w postaci tensora) oraz nagłówków (w postaci konkretnego indeksu z listy 'classes') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:50.063029600Z",
     "start_time": "2023-11-03T14:48:41.964636200Z"
    }
   },
   "id": "ad0e6241eb055ee0"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog  plane deer  car  \n"
     ]
    }
   ],
   "source": [
    "imshow(torchvision.utils.make_grid(images))             # tworzenie siatki obrazków oraz używanie funkcji do wyświetlania tej siatki \n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(BATCH_SIZE)))      # wyświetlanie kolejnych nagłówków do każdego obrazka"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:50.179136300Z",
     "start_time": "2023-11-03T14:48:50.059027400Z"
    }
   },
   "id": "fcb7eacf7401c15b"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class Net(nn.Module):                                                           # tworzenie modelu, model musi dziedziczyć po klasie nn.Module\n",
    "    def __init__(self):                                             \n",
    "        super().__init__()                                                      # dziedziczenie wszystkich funkcji\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)    # stworzenie pierwszej warstwy filtrów nakładanych na obraz która przyjmuje 3 kanały, oddaje 6 kanałów przefiltrowanych a wielkość filtra to 5px na 5px. Rozmiar jaki trafia do tej warstwy to (3x32x32) po zastosowaniu wzoru na wymiar wyjściowy:\n",
    "        # wymiar wyjściowy = ((wymiar wejściowy - rozmiar filtra + 2*padding) / Stride) + 1\n",
    "        # w tym przypadku z wymiaru 3x32x32 powstanie: 6 x 32-5+1 x 32-5+1 -> 6x28x28            3x32x32->6x28x28\n",
    "            \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)       # określanie funkcji która wyciąga maksymalną wartość z pola (2px na 2px) co pozwala na wyostrzenie najbardziej charakterystycznych pixeli zmniejsza nam to rozmiar wejściowy o połowę w naszym przypadku:                                                  6x28x28 -> 6x14x14\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)   # kolejna warstwa przyjmuje 6 kanałów (bo wyprodukowaliśmy z 3 kanałów -> 6 kanałów) i tworzymy z 6 kanałów -> 16 kanałów z filtrem wielkości 5px na 5px \n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)   # tutaj już następuje uczenie się modelu, dla macierzy wejściowej tworzona jest randomowa macierz z wagami oraz bias które automatycznie będą się dostrajały podczas uczenia, pierwszym argumenetem jest liczba danych wejściowych (neuronów) która oznacza kolejno liczbę kanałów, wysokość i szerokość a jest ona inna niż (3x32x32) ze względu na poprzednie operacje. Drugi argument czyli liczba neuronów wyjściowych w tym przypadku 120 jest wybierana metodą prób i błędów, nie ma zasady co do ustalania wartości tego argumenyu (nie za dużo nie za mało)\n",
    "        \n",
    "        self.fc2 = nn.Linear(120, 84)           # liczba neuronów wyjściowych z poprzedniej warstwy musi zgadzać się z liczbą neuronów wejściowych w tej warstwie.\n",
    "        \n",
    "        self.fc3 = nn.Linear(84, 10)            # finalnie tworzymy 10 neuronów bo jest już to nasz ostateczny wynik, wagi i biasy będą dostosowywane w taki sposób aby znaleźć zależności pomiędzy poszczególnymi klasami \n",
    "        # klas mamy 10 dlatego ostatecza warstwa musi wyprodukować 10 neuronów wyjściowych. \n",
    "\n",
    "    def forward(self, x):                       # nadpisujemy funckję forward \n",
    "        \n",
    "        # x = self.pool(F.relu(self.conv1(x)))  to samo co na dole ale w jednej linii \n",
    "        x = self.conv1(x)   # (warstwa konwolucyjna) funkcja nn.Conv2d(..) nakładamy filtry, tworzymy mapę charakterystycznych cech. W tym przypadku x -> (3,32,32) po tej warstwie x -> (6,28,28)\n",
    "        x = F.relu(x)       # (funckja aktywacji) relu: x>=0 -> x;  x<0 -> 0, odcina wartości ujemne i ustawia je na wartość 0, co sprawia że model nie skupia się na tych wartości. Ta funckja nie zmienia rozmiaru\n",
    "        x = self.pool(x)    # funkcja MaxPool2d(..) wyciąga maksymalne wartości z określonego pola w tym przypadku 2px na 2px co w tym przypadku sprawia że x -> (6,28,28) = x -> (6,14,14)\n",
    "        # podsumowanie: \n",
    "        # nakładamy filtry które generują nam dodatkowe kanały, odcinamy nie interesujące nas wartości ujemne po czym wyciągamy najbardziej charakterystyczne wartości. Podczas tych wszystkich operacji rozmiar danych ulega zmianie z wejścia (3x32x32) -> (6x28x28)\n",
    "        \n",
    "        # x = self.pool(F.relu(self.conv2(x)))  to samo co na dole ale w jednej linii \n",
    "        # kontynuujemy nakładanie filtrów, tym razem ze względu na poprzednie operacje wejściowe dane mają rozmiar (6,28,28)\n",
    "        x = self.conv2(x)   # kolejna warstwa konwolucyjna nn.Conv2d(..) znowu nakładamy filtry, tworzymy mapę charakterystycznych cech. W tym przypadku x -> (6,14,14) po tej warstwie x -> (16,10,10)\n",
    "        x = F.relu(x)       # funckja aktywacji relu: x>=0 -> x;  x<0 -> 0, odcina wartości ujemne i ustawia je na wartość 0, co sprawia że model nie skupia się na tych wartości. Ta funckja nie zmienia rozmiaru\n",
    "        x = self.pool(x)    # funkcja MaxPool2d(..) wyciąga maksymalne wartości z określonego pola w tym przypadku 2px na 2px co w tym przypadku sprawia że x -> (16,10,10) = x -> (16,5,5)\n",
    "        # podsumowanie: po wszystkich tych operacjach rozmiar naszych danych (neuronów) to:\n",
    "        \"\"\"(16 x 5 x 5)\"\"\"\n",
    "        \n",
    "        x = torch.flatten(x, 1)     # spłaszczamy nasz tensor po wszystkich filtrach, ponieważ warstwa sieci neuronowej Linear przyjmuje dane w takiej postaci, zostawiamy tylko wymiar batch'a co w rezultacie daje rozmiar (4, 16*5*5) = (4, 400)\n",
    "        \n",
    "        # x = F.relu(self.fc1(x))   # to samo co na dole ale w jednej linii \n",
    "        x = self.fc1(x)     # stosujemy warstwę sieci neuronowej, towrzona jest macierz wag i bias które będą dostosowywane w kolejnych krokach (chyba?). Funkcja przyjmuje liczbę neuronów (16*5*5)=400 i produkuje 120 neuronów  \n",
    "        x = F.relu(x)       # znowu funkcja relu (aktywacji) 'eliminująca' wartości ujemne aby model 'skupił' na najważniejszych wartościach \n",
    "        \n",
    "        # x = F.relu(self.fc2(x))   # to samo co na dole ale w jednej linii \n",
    "        x = self.fc2(x)             # kolejna warstwa sieci neuronowej w tym przypadku przyjmująca 120 neuronów wejściowych i produkująca 84 neurony \n",
    "        x = F.relu(x)               # odcinanie wartości najmniej interesujących za pomocą funkcji aktywacji\n",
    "        \n",
    "        x = self.fc3(x)             # ostatnia warstwa sieci neuronowej przyjmująca 84 neurony i finalnie produkująca 10 neuronów czyli tyle ile jest klas w zestawie danych CIFAR10 każdy neuron to każda klasa\n",
    "        return x                    # rozmiar wyniku to 4,10 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:50.270218800Z",
     "start_time": "2023-11-03T14:48:50.177134600Z"
    }
   },
   "id": "c3f1b8385ce8ee67"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "net = Net()                             # tworzymy instancję modelu\n",
    "criterion = nn.CrossEntropyLoss()       # tworzymy funkcję straty dla problemu kasyfikacji z jakim spotykamy się w tym przypadku, stostuje się ją wraz z ostatnią warstwą sieci neuronowych \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:48:50.270218800Z",
     "start_time": "2023-11-03T14:48:50.187144100Z"
    }
   },
   "id": "f1f21efd37dad746"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.209\n",
      "tensor([8, 3, 9, 9])\n",
      "[1,  4000] loss: 1.216\n",
      "tensor([6, 0, 9, 7])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 15\u001B[0m\n\u001B[0;32m     11\u001B[0m outputs \u001B[38;5;241m=\u001B[39m net(inputs)\n\u001B[0;32m     13\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)       \u001B[38;5;66;03m# porównuje wyniki, które zgaduje model z aktualnymi wynikami, i porównuje je obliczając stratę sprawdzając przy tym jak dobrze model sie uczy\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     19\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"TRAIN THE NETWORK\"\"\"\n",
    "for epoch in range(2):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "    \n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)       # porównuje wyniki, które zgaduje model z aktualnymi wynikami, i porównuje je obliczając stratę sprawdzając przy tym jak dobrze model sie uczy\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss/2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print(\"training finished\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T15:06:03.804342800Z",
     "start_time": "2023-11-03T15:05:36.954784600Z"
    }
   },
   "id": "7d4a7a5537015af7"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:50:31.406323200Z",
     "start_time": "2023-11-03T14:50:31.370289200Z"
    }
   },
   "id": "a19436010a00fba5"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('conv1.weight',\n              tensor([[[[-5.0296e-02, -1.8364e-03, -2.0723e-02,  2.4244e-01,  2.2545e-01],\n                        [-6.3138e-02,  1.8856e-01,  2.0922e-01,  3.0623e-01,  1.9566e-02],\n                        [ 3.8000e-01,  3.8474e-01,  4.6169e-01,  1.9311e-01, -1.4501e-01],\n                        [ 1.7159e-01, -2.1267e-02, -1.5533e-01, -3.2017e-01, -1.5754e-01],\n                        [-2.3740e-01, -4.0542e-01, -4.4859e-01, -3.9616e-01, -1.3137e-01]],\n              \n                       [[-1.8473e-01,  1.0955e-02, -1.7179e-01,  1.4847e-01,  4.5916e-02],\n                        [-1.0548e-01,  3.6643e-02,  2.9070e-02,  1.1976e-01, -1.4565e-01],\n                        [ 2.6180e-01,  3.6512e-01,  2.2146e-01,  9.4449e-02, -8.3563e-02],\n                        [ 2.5550e-01, -1.2322e-02, -9.5066e-02, -2.4840e-01, -1.2907e-01],\n                        [-1.1859e-01, -3.9232e-01, -3.6541e-01, -2.5935e-01,  1.6796e-01]],\n              \n                       [[-7.0611e-02, -8.5522e-02, -6.7626e-02,  3.5620e-02,  1.5350e-01],\n                        [-2.4547e-01, -1.5761e-01, -2.0232e-01, -3.2205e-02, -2.0646e-01],\n                        [ 2.6026e-01,  2.3069e-01,  2.8412e-01, -2.8122e-02, -1.9014e-01],\n                        [ 1.3901e-01,  2.1204e-01, -5.9371e-03, -9.1158e-05, -1.1209e-01],\n                        [-6.5221e-02, -1.9939e-01, -1.7556e-01,  1.2396e-01,  3.4064e-01]]],\n              \n              \n                      [[[ 2.6034e-01,  2.2883e-01,  2.4481e-01,  3.8920e-01,  1.9707e-01],\n                        [ 1.5828e-01,  1.7005e-01,  3.0280e-01,  1.9469e-01,  1.7426e-01],\n                        [ 2.3818e-02,  1.3257e-01,  1.4650e-01,  2.8722e-01,  3.2777e-01],\n                        [-1.9828e-01, -1.5664e-01,  6.7112e-02,  1.1226e-02,  1.0282e-01],\n                        [-2.4738e-01, -3.2752e-01, -2.5980e-01, -1.7843e-01, -8.6630e-02]],\n              \n                       [[-2.5027e-01, -2.2820e-01, -2.3464e-01, -2.1179e-01, -2.7853e-01],\n                        [-3.6892e-01, -1.0090e-01, -1.7807e-01, -1.3379e-01, -2.8445e-01],\n                        [-3.5280e-01, -2.2872e-01, -1.1523e-01, -1.9897e-01, -8.6342e-02],\n                        [-2.9189e-01, -2.2721e-01, -2.3395e-01, -1.1666e-01, -7.0032e-02],\n                        [-1.6814e-01, -3.0070e-01, -3.2695e-01, -2.6563e-01,  9.1208e-02]],\n              \n                       [[-3.6097e-02,  1.6182e-01,  8.0244e-02, -1.0993e-01, -2.4352e-03],\n                        [-4.4801e-02,  3.4113e-03, -6.9448e-02, -1.2221e-01, -4.8637e-02],\n                        [ 7.6892e-03,  1.6788e-01,  5.5863e-02,  2.0088e-01,  1.0489e-02],\n                        [ 2.9417e-02,  8.3914e-02,  1.4717e-01,  2.0437e-01,  2.5764e-01],\n                        [ 2.6133e-02,  2.1165e-02, -1.2722e-01, -2.7306e-02,  4.4995e-03]]],\n              \n              \n                      [[[ 2.3889e-01,  2.4519e-02,  5.3542e-02,  5.2060e-02,  8.7901e-02],\n                        [-1.1308e-01,  4.8096e-02,  4.1991e-03,  1.5257e-01,  5.8200e-02],\n                        [-7.0215e-02, -8.8064e-02,  3.1429e-03,  2.7384e-01,  1.4442e-01],\n                        [-1.3982e-01, -6.6436e-02,  1.1044e-01,  2.2667e-01,  5.3626e-02],\n                        [-1.2109e-01, -2.2861e-03,  3.7058e-02,  1.3269e-01,  1.4202e-01]],\n              \n                       [[-1.1039e-01, -1.0934e-02, -6.0350e-02, -1.6366e-02,  6.4568e-03],\n                        [-1.7045e-01, -1.5834e-01, -8.0947e-02,  8.9353e-02,  1.4630e-01],\n                        [-3.0458e-01, -2.6727e-01, -9.9064e-02,  2.1023e-01,  2.2182e-01],\n                        [-2.7266e-01, -2.0076e-01,  3.0275e-03,  1.1836e-01,  1.0917e-01],\n                        [-1.8606e-01, -2.2857e-01, -4.6171e-02,  1.2012e-01,  6.7202e-02]],\n              \n                       [[-3.4947e-02, -1.1332e-01, -1.2500e-01, -1.6906e-02,  1.3594e-01],\n                        [-2.4229e-01, -1.6808e-01, -1.0931e-02,  1.5888e-01,  2.6937e-01],\n                        [-4.0045e-01, -1.5842e-01,  2.2589e-02,  2.8890e-01,  3.7143e-01],\n                        [-3.3901e-01, -2.3553e-01,  1.9873e-01,  2.8076e-01,  2.6453e-01],\n                        [-2.8016e-01,  4.2149e-02,  2.3424e-01,  2.9130e-01,  1.5495e-01]]],\n              \n              \n                      [[[-3.7282e-03,  8.1727e-02,  1.6881e-01,  1.5626e-01,  6.3439e-02],\n                        [ 1.2734e-01,  1.3108e-01, -1.4653e-01,  5.8687e-02, -3.4089e-02],\n                        [-4.1040e-02,  2.7199e-01, -4.9998e-01,  1.1484e-01,  2.0573e-02],\n                        [ 3.3623e-01,  2.5258e-01, -8.1508e-01,  2.6082e-01,  2.0446e-01],\n                        [ 4.0274e-01,  7.5644e-02, -7.9997e-01,  6.5425e-02,  7.8320e-02]],\n              \n                       [[-4.5879e-02, -8.9914e-02, -1.6904e-02, -5.9835e-02, -3.8378e-04],\n                        [ 1.1865e-01,  1.2932e-01, -3.2110e-01,  2.2228e-01,  5.3755e-02],\n                        [ 8.0070e-02,  2.5476e-01, -5.3342e-01,  1.6597e-01,  1.2981e-01],\n                        [ 2.2482e-01,  3.2054e-01, -8.7036e-01,  3.7732e-01,  4.2429e-01],\n                        [ 4.3596e-01,  7.3934e-02, -7.7333e-01,  2.0969e-01,  2.8997e-01]],\n              \n                       [[-2.2008e-01, -3.3957e-02, -1.4753e-01, -7.4690e-02, -3.1770e-01],\n                        [-3.5710e-02,  2.4010e-02, -2.8948e-01,  1.9192e-01,  3.0337e-02],\n                        [-5.1170e-02,  1.5040e-01, -4.7488e-01,  5.0677e-02, -9.7285e-02],\n                        [ 2.6618e-01,  2.0602e-01, -7.3945e-01,  2.7776e-01,  1.3919e-01],\n                        [ 1.7492e-01,  9.8644e-02, -6.3657e-01,  8.0927e-02, -3.7875e-02]]],\n              \n              \n                      [[[-1.6217e-01, -1.8491e-01, -3.4167e-01, -1.6260e-01, -6.8764e-02],\n                        [ 2.7861e-03,  4.1521e-02, -6.6198e-02, -2.5370e-01, -2.8061e-02],\n                        [ 1.6589e-01,  1.7843e-01,  2.3398e-01,  2.0831e-01,  3.2287e-02],\n                        [ 1.5010e-01,  1.1804e-01,  1.6050e-01,  3.1741e-01,  2.0574e-01],\n                        [ 5.0809e-02,  4.2660e-02,  4.8265e-02,  6.7371e-02,  4.1049e-02]],\n              \n                       [[-5.6953e-03, -1.1726e-01, -2.0120e-01, -1.8295e-01, -3.7061e-03],\n                        [ 7.0295e-02, -1.4368e-01, -1.5036e-01, -1.0989e-01, -1.3348e-01],\n                        [-3.3781e-02,  5.8338e-02,  2.6864e-02, -7.3098e-02, -1.7053e-01],\n                        [-1.1229e-01,  7.4008e-03,  1.6574e-01,  3.0647e-02, -1.0647e-01],\n                        [ 4.3952e-03,  3.7304e-02,  6.9289e-02,  1.2723e-01,  9.7380e-03]],\n              \n                       [[-1.9863e-02, -1.3735e-01, -1.4532e-01, -1.2380e-01, -2.1469e-02],\n                        [ 1.9041e-01, -6.4037e-02, -1.9818e-01, -2.8771e-01, -1.1947e-01],\n                        [ 1.0478e-01,  1.4770e-01,  1.1835e-01, -7.4387e-02, -1.7675e-01],\n                        [ 9.4585e-02,  2.7981e-01,  2.2655e-01,  1.1873e-01,  2.8251e-02],\n                        [ 3.8948e-02,  8.9507e-02,  1.5930e-01,  2.3024e-01,  1.5076e-01]]],\n              \n              \n                      [[[-2.3717e-01, -4.7119e-02, -3.1550e-01, -1.5742e-01, -3.4117e-02],\n                        [-2.5861e-03,  1.6240e-01, -1.0883e-01, -9.9356e-02,  2.4854e-02],\n                        [ 3.8217e-02,  2.4588e-01,  2.1189e-01,  2.3952e-01,  1.2826e-01],\n                        [-3.0209e-01, -3.0789e-01, -3.7405e-01, -2.2645e-01, -1.6841e-01],\n                        [-2.3794e-01, -1.9296e-01, -1.5782e-01, -1.1123e-01, -3.5638e-02]],\n              \n                       [[-9.7856e-02, -1.8517e-01, -2.9547e-01, -1.8133e-01, -9.1816e-02],\n                        [ 1.5140e-01,  1.4426e-01,  7.3729e-02,  2.1345e-01,  1.6475e-01],\n                        [ 3.1024e-01,  3.9694e-01,  4.0535e-01,  4.0365e-01,  1.9719e-01],\n                        [-2.6814e-01, -1.0460e-01, -1.9143e-01, -1.9051e-01,  1.7498e-02],\n                        [ 3.7247e-03, -7.8370e-02, -2.2180e-01, -1.8970e-01, -1.9656e-03]],\n              \n                       [[ 3.1695e-02,  3.2436e-02, -1.2837e-01, -1.0037e-01,  1.1200e-01],\n                        [ 4.9541e-03,  1.9743e-01,  2.3117e-02,  6.5249e-02,  1.0012e-01],\n                        [ 2.1825e-01,  3.4602e-01,  4.5326e-01,  2.9311e-01,  3.4526e-01],\n                        [ 1.0139e-02, -9.6335e-02, -1.9099e-01,  3.3365e-02,  9.0550e-02],\n                        [-5.9673e-02, -6.5773e-03, -2.2736e-01, -1.0191e-01,  1.1888e-01]]]])),\n             ('conv1.bias',\n              tensor([-0.4198, -0.5862, -0.2220, -0.0794, -0.3807, -0.3193])),\n             ('conv2.weight',\n              tensor([[[[-4.3058e-02,  1.6994e-02, -4.9254e-02, -1.6321e-02,  7.5856e-02],\n                        [-5.6093e-02, -1.4898e-01, -6.4068e-02,  2.0822e-01, -5.9944e-02],\n                        [-1.7149e-02, -1.7742e-03,  2.7355e-01,  1.9683e-02, -2.0950e-01],\n                        [ 1.4243e-01,  2.0662e-01,  1.3252e-01, -1.8348e-01, -1.0037e-01],\n                        [ 1.8146e-01,  1.4004e-01, -4.0306e-02, -7.9617e-02, -1.1916e-01]],\n              \n                       [[-2.7515e-02,  3.0564e-02, -5.6664e-02,  1.0519e-01,  3.9963e-01],\n                        [-1.5039e-02, -4.7020e-02, -7.9682e-02,  4.4318e-02,  2.5522e-01],\n                        [-6.2984e-02, -3.7859e-02,  1.0514e-01,  9.4417e-02,  5.8863e-02],\n                        [ 2.9309e-02,  2.1939e-02,  1.1223e-01,  2.8530e-02, -8.1232e-02],\n                        [-5.2938e-02, -9.5999e-02, -1.3175e-01, -2.3420e-01, -2.3361e-01]],\n              \n                       [[ 1.0606e-01, -5.7984e-02,  3.6528e-02, -1.7885e-01, -3.5924e-01],\n                        [-3.0363e-02,  1.5022e-01, -1.1114e-01, -2.9610e-01,  4.3393e-02],\n                        [ 5.1562e-02,  1.0054e-01, -1.6151e-01, -4.5814e-02,  3.7710e-01],\n                        [-7.8888e-02, -5.1763e-02, -4.9973e-02,  2.5279e-01,  1.8221e-01],\n                        [-4.5954e-02, -1.2066e-01,  7.1528e-02,  1.1913e-01, -1.5263e-01]],\n              \n                       [[ 1.0525e-01,  5.1909e-02,  9.8143e-03, -1.7447e-01,  3.7163e-01],\n                        [ 3.3662e-02,  1.9795e-01, -2.2443e-01,  3.0941e-01,  2.7189e-01],\n                        [-5.3675e-02,  8.4944e-02,  5.5467e-02,  4.0836e-01, -1.4693e-01],\n                        [-1.3545e-01, -4.6391e-02,  4.6941e-02, -2.9542e-02, -2.9195e-01],\n                        [-1.9250e-01, -1.6901e-01, -1.6869e-01, -3.1435e-01, -1.6742e-01]],\n              \n                       [[-5.8441e-02, -3.4490e-02, -5.2988e-02, -1.7118e-01, -9.5262e-02],\n                        [-2.3441e-01, -2.3610e-01, -2.1161e-01, -2.4610e-01, -5.2266e-02],\n                        [-1.1741e-01, -1.8731e-01, -2.5816e-01, -1.0828e-01,  1.1377e-01],\n                        [-6.3403e-02, -9.5925e-02, -1.8000e-02,  2.8072e-02,  7.5668e-02],\n                        [ 1.2426e-01,  3.2766e-02,  1.8550e-01,  1.4953e-01, -5.6310e-02]],\n              \n                       [[ 1.3982e-01, -6.6665e-04,  5.3772e-02, -2.2303e-04,  1.3054e-02],\n                        [ 9.1604e-02,  1.1843e-01, -3.8457e-02, -6.3522e-02, -9.6212e-02],\n                        [ 1.0803e-02,  5.3958e-02, -7.8085e-02, -5.3401e-02, -1.3046e-01],\n                        [ 8.1915e-02,  1.4357e-01, -1.3123e-01, -1.3966e-01, -9.3008e-02],\n                        [-1.4246e-01, -1.4345e-01, -1.4082e-01, -1.4512e-01, -1.3690e-01]]],\n              \n              \n                      [[[ 7.4185e-02, -4.6849e-02, -1.4162e-02,  8.1954e-02,  7.2562e-02],\n                        [ 6.6989e-02,  5.4505e-02, -1.3382e-03, -2.6502e-02,  9.9888e-02],\n                        [-1.4739e-01, -1.4898e-01, -1.8698e-01, -1.7393e-01, -1.1227e-01],\n                        [-3.1803e-03,  5.0431e-02,  9.2804e-02, -1.7311e-02,  9.3220e-02],\n                        [-7.8259e-02, -8.2535e-02, -4.6129e-02, -1.8697e-02, -2.3547e-02]],\n              \n                       [[-8.4468e-02, -1.4723e-01, -1.1449e-01, -1.2059e-01, -8.7849e-02],\n                        [ 7.2987e-02, -4.8942e-02,  8.1281e-02,  9.4271e-02, -6.8986e-02],\n                        [-2.8172e-02, -2.5311e-03, -5.3908e-02,  1.6806e-02, -9.3804e-02],\n                        [ 7.3167e-02, -2.7469e-02,  5.5038e-02,  5.9053e-02, -3.0959e-02],\n                        [ 9.8208e-02,  4.0942e-02, -4.4520e-02, -3.3970e-03,  3.3113e-02]],\n              \n                       [[ 3.9354e-02,  3.6862e-02, -1.2742e-01,  1.0598e-01,  4.6371e-02],\n                        [ 2.5756e-02, -4.4868e-02, -1.1512e-01,  4.6796e-02, -9.4484e-02],\n                        [ 1.8757e-02, -7.9930e-02, -6.7080e-02,  8.2914e-02, -9.6221e-02],\n                        [ 5.3213e-02, -1.4086e-01, -1.1553e-01,  1.9266e-02, -2.5814e-02],\n                        [ 2.5317e-02, -8.1203e-02, -8.8935e-02,  6.1555e-02, -7.5436e-02]],\n              \n                       [[ 2.4287e-01, -1.5613e-01,  9.6048e-02, -1.3299e-01, -2.8056e-02],\n                        [ 2.2891e-01, -3.6413e-02,  2.7016e-01, -3.4428e-02,  7.8155e-02],\n                        [ 2.6136e-01, -1.4935e-01,  3.4718e-01, -1.9474e-01,  1.3584e-01],\n                        [ 2.0628e-01, -3.0112e-01,  1.4442e-01, -2.3758e-01, -1.9483e-03],\n                        [-2.0659e-02, -2.3677e-01,  1.6036e-04, -2.7712e-01, -3.9104e-02]],\n              \n                       [[-8.2614e-02,  1.0640e-02,  2.2809e-02, -4.2856e-02,  1.6885e-01],\n                        [-6.6576e-02, -4.9091e-02, -1.5908e-01, -2.3499e-02,  1.1272e-02],\n                        [-1.0492e-01,  1.6468e-02, -1.6218e-02,  5.2891e-02,  3.8173e-02],\n                        [ 4.2215e-02,  6.0318e-02, -2.5622e-02, -3.4060e-02,  6.7839e-02],\n                        [ 9.4048e-02, -2.8658e-02,  2.5632e-02,  9.3247e-02,  8.9164e-02]],\n              \n                       [[ 3.2903e-02, -3.9682e-02,  3.4980e-02,  1.5128e-01,  1.7941e-01],\n                        [ 7.7908e-02,  8.7686e-02,  1.4750e-01,  1.9366e-01,  6.5446e-02],\n                        [-1.7268e-01, -1.1006e-01, -2.0874e-01, -1.7395e-01, -9.1209e-02],\n                        [ 8.4091e-02,  1.5659e-01,  1.6794e-01,  1.7353e-01,  1.9713e-01],\n                        [-9.8284e-02, -6.2563e-02, -4.1940e-02, -1.8469e-01, -8.4966e-02]]],\n              \n              \n                      [[[-6.2166e-02, -1.2488e-01, -1.5261e-01, -1.8017e-01, -1.8830e-01],\n                        [ 3.4235e-03, -1.2771e-01, -2.5084e-01, -2.5915e-01, -7.8483e-02],\n                        [ 5.5144e-02, -3.5847e-02, -1.7358e-01, -1.5337e-01, -5.3342e-02],\n                        [-3.7956e-02, -8.8454e-02, -1.3995e-02,  1.2468e-02,  1.6987e-02],\n                        [-9.8519e-02, -8.7201e-02, -5.4613e-02,  1.3270e-02,  5.0926e-04]],\n              \n                       [[-2.1765e-01, -7.4516e-02, -1.0294e-01, -1.5855e-01, -1.3935e-02],\n                        [-1.1373e-01,  1.8893e-02,  1.8007e-02, -1.2852e-01, -6.6940e-03],\n                        [-8.8665e-02,  3.4072e-02,  1.0364e-01,  4.0953e-02,  1.4812e-01],\n                        [-3.5618e-02,  7.4067e-02, -9.7896e-03,  1.0178e-01,  2.2452e-02],\n                        [-5.5517e-02,  4.4690e-02,  6.4815e-02,  9.2305e-02, -3.6024e-02]],\n              \n                       [[-6.6897e-02, -1.3036e-01, -1.2130e-01, -1.0546e-02,  1.0783e-01],\n                        [ 4.4034e-02, -4.8346e-02, -8.3737e-02, -9.7895e-02,  7.0381e-02],\n                        [ 1.3793e-01,  9.6931e-02, -7.5033e-02, -2.6521e-02, -3.2379e-02],\n                        [ 7.8557e-02,  1.0202e-01, -2.2675e-02,  4.6687e-02, -1.2278e-01],\n                        [ 2.7865e-02,  5.2582e-02, -5.9848e-02, -8.3028e-02, -2.3772e-01]],\n              \n                       [[-9.1017e-02, -3.1604e-01, -3.6531e-01, -2.6517e-01, -2.3820e-01],\n                        [-3.4152e-02, -3.5637e-01, -3.9601e-01, -3.4838e-01, -2.4246e-01],\n                        [ 1.3046e-01, -9.1334e-03, -1.2021e-01, -1.1512e-01,  2.6550e-02],\n                        [ 2.6850e-01,  8.9026e-02,  1.1914e-02, -2.4183e-02,  6.0120e-02],\n                        [ 3.3151e-01,  2.3989e-01,  1.9804e-01,  1.3909e-01,  1.7604e-01]],\n              \n                       [[ 1.3471e-01, -8.8668e-03,  8.1176e-02, -6.3015e-02, -5.8325e-02],\n                        [ 2.3187e-01,  1.6006e-01,  8.6017e-02,  8.4004e-02,  2.4046e-02],\n                        [ 2.6202e-02,  6.2810e-02, -5.1935e-02, -6.8793e-02, -1.3100e-01],\n                        [-4.6187e-02,  3.8586e-02, -4.4504e-02, -2.0322e-02, -1.1566e-01],\n                        [ 1.4943e-02,  7.1201e-02,  3.1976e-03,  1.4976e-02,  5.4237e-02]],\n              \n                       [[ 1.2336e-01,  1.2717e-01,  7.3577e-02,  7.7001e-02,  1.9673e-01],\n                        [ 1.4143e-01,  1.1514e-01,  1.3941e-01,  1.5136e-01,  2.0725e-01],\n                        [ 1.1380e-01,  5.2838e-02, -9.8434e-03,  1.2804e-02,  4.2520e-02],\n                        [ 2.1503e-02,  1.4138e-02,  1.0959e-01,  4.8107e-03, -3.4702e-03],\n                        [ 1.3532e-02, -5.5697e-02,  5.3786e-02,  5.1804e-02,  7.9125e-03]]],\n              \n              \n                      ...,\n              \n              \n                      [[[-2.4920e-02,  7.9504e-02,  1.3786e-01,  5.4087e-02, -2.3480e-02],\n                        [ 7.9428e-02, -7.6888e-02,  5.9117e-02, -2.4608e-02,  5.9225e-02],\n                        [-1.4305e-02, -4.3582e-02,  1.3356e-02,  1.0709e-01,  1.3917e-01],\n                        [ 4.4330e-02, -2.4226e-02, -2.2183e-02, -9.0861e-03, -3.2772e-02],\n                        [-5.3367e-02, -1.3552e-01, -9.7557e-02,  9.9831e-02,  4.0936e-02]],\n              \n                       [[ 8.9959e-02, -1.9665e-03,  9.8457e-03,  6.5565e-02, -7.4426e-02],\n                        [-3.2017e-02, -4.7374e-03, -4.5277e-03, -1.2964e-01, -5.0353e-02],\n                        [-1.7660e-02, -3.5815e-04,  1.7459e-02, -8.2223e-02, -8.7252e-02],\n                        [ 1.0023e-01,  1.1935e-01,  2.3046e-02, -8.3014e-02, -1.3993e-01],\n                        [ 7.8336e-02,  1.3402e-01,  1.0107e-01,  6.0031e-02, -5.8597e-02]],\n              \n                       [[ 2.1333e-01,  4.4882e-02,  9.9966e-02,  7.4067e-02,  2.5832e-01],\n                        [-5.5007e-02,  7.4953e-02, -2.6722e-02,  1.0637e-01,  2.3418e-01],\n                        [-7.3430e-02, -1.7635e-02,  1.6864e-02,  4.9130e-02,  1.1141e-01],\n                        [-5.9746e-02,  1.1539e-01,  8.8274e-02, -7.7858e-02, -6.2033e-02],\n                        [-2.5853e-02, -6.3894e-02, -3.4615e-02, -1.4504e-01, -8.1670e-02]],\n              \n                       [[ 1.2839e-01,  1.1266e-01,  1.4025e-01,  1.9764e-01,  8.9900e-02],\n                        [ 7.0201e-02,  1.4954e-01, -3.9645e-02, -3.1387e-02, -3.6308e-02],\n                        [-4.8672e-02, -2.9619e-02, -1.6072e-01, -1.3200e-01, -1.1684e-01],\n                        [-1.6374e-01, -3.0767e-01, -3.4442e-01, -3.6243e-01, -3.2610e-01],\n                        [-3.9278e-01, -5.2137e-01, -4.1537e-01, -4.1267e-01, -3.5312e-01]],\n              \n                       [[ 5.5505e-02,  1.1762e-01, -7.9537e-02, -4.4243e-03,  8.4416e-02],\n                        [-2.9414e-02, -1.3524e-02,  4.3040e-02,  7.6787e-02, -4.4589e-03],\n                        [ 1.7104e-01,  7.4738e-02,  2.5901e-02,  1.1982e-01, -2.0782e-02],\n                        [ 1.8081e-01,  1.5635e-01,  1.0138e-01,  1.5633e-01,  2.7225e-02],\n                        [ 1.0101e-01,  1.7964e-02,  2.2966e-02,  1.3608e-02,  1.1799e-01]],\n              \n                       [[ 2.7506e-02,  3.8950e-02,  3.9744e-02, -4.9099e-03, -6.4472e-02],\n                        [ 3.0494e-02, -1.6642e-02, -9.5445e-02,  6.3470e-02,  5.6112e-02],\n                        [-3.3424e-02, -7.9962e-02,  2.3069e-02,  3.1532e-02,  1.4600e-01],\n                        [ 9.1979e-02, -1.6462e-03,  6.8271e-02, -9.2511e-02, -9.9827e-02],\n                        [-1.6256e-01, -9.7256e-02,  2.5712e-02,  1.2040e-01,  6.1914e-02]]],\n              \n              \n                      [[[ 2.5909e-02,  8.4264e-02,  9.9014e-02,  5.9907e-02,  4.3845e-02],\n                        [ 5.6262e-02,  1.2049e-01,  2.6743e-01,  2.2371e-01,  1.9168e-01],\n                        [ 1.1296e-02,  3.5188e-02, -2.8603e-02,  2.3062e-02,  3.0125e-02],\n                        [-9.8750e-02, -9.9154e-02, -1.9058e-01, -1.5914e-01, -6.6137e-02],\n                        [-3.7762e-02, -6.2767e-02,  4.5650e-02, -5.0089e-02, -5.1503e-02]],\n              \n                       [[ 6.1456e-02,  8.9194e-02,  8.4998e-02,  1.4344e-01,  3.2854e-02],\n                        [ 1.0106e-01,  1.6367e-01,  2.4333e-01,  2.0811e-01,  2.2032e-01],\n                        [ 4.2976e-03,  8.2573e-02,  6.6319e-02,  9.8856e-02,  3.7211e-02],\n                        [-2.4171e-01, -2.0780e-01, -1.7214e-01, -1.2726e-01, -1.5742e-01],\n                        [-1.4978e-01, -1.7901e-01, -1.8630e-01, -1.6434e-01, -1.3053e-01]],\n              \n                       [[-7.3266e-02, -1.1082e-01, -8.4236e-03, -1.2928e-01, -6.1298e-02],\n                        [-9.0782e-02, -7.1952e-02, -5.9113e-02, -5.1210e-02, -9.8662e-02],\n                        [-1.3218e-01, -1.6417e-01, -1.4562e-01, -8.0188e-02, -7.6762e-02],\n                        [-6.6213e-02, -9.6287e-02, -5.2610e-02, -7.7219e-02, -1.1543e-01],\n                        [-1.0319e-01, -3.4471e-02, -4.5123e-02, -7.4820e-02, -1.2735e-01]],\n              \n                       [[ 3.1369e-02,  1.2833e-01,  6.3895e-02,  1.6916e-02,  2.8172e-02],\n                        [-7.2096e-03,  5.5449e-02,  8.0194e-02,  7.1661e-02, -2.3136e-04],\n                        [ 7.0323e-02, -7.3639e-03, -4.2357e-02,  5.9642e-02,  5.7313e-03],\n                        [-8.6893e-02, -1.2712e-01, -1.3362e-01, -1.5649e-01, -1.2965e-01],\n                        [-2.2710e-01, -2.3386e-01, -2.4927e-01, -1.7977e-01, -1.9471e-01]],\n              \n                       [[ 3.4252e-02,  7.2431e-02,  1.3065e-02, -1.1582e-02, -3.6389e-03],\n                        [-1.2456e-02,  5.0498e-03,  1.5639e-01,  1.0425e-01,  4.8742e-02],\n                        [-2.6434e-02,  2.7966e-02, -5.8809e-02, -2.3020e-02, -2.6795e-02],\n                        [-3.7768e-03, -4.3781e-02, -1.0032e-01,  2.0408e-02, -8.4858e-02],\n                        [ 1.1477e-01, -4.5988e-02, -3.2795e-02, -2.5632e-02, -1.0617e-01]],\n              \n                       [[ 8.7116e-02, -4.3539e-02, -2.5429e-02, -9.8485e-02, -4.5707e-03],\n                        [ 4.5397e-02,  1.0866e-01,  8.7041e-02,  8.1171e-02,  2.1045e-01],\n                        [-7.7467e-02, -3.8765e-02, -1.4105e-01, -8.2185e-02, -4.2627e-03],\n                        [ 3.6958e-02, -4.5495e-02, -1.2354e-01, -3.7729e-02, -1.3296e-02],\n                        [ 3.0303e-02,  2.7573e-02, -4.1516e-02,  3.9256e-02,  1.8280e-02]]],\n              \n              \n                      [[[ 2.1840e-01,  8.6143e-02,  8.5990e-02,  1.7031e-01,  1.9848e-01],\n                        [ 6.1621e-02,  3.3982e-02,  1.0117e-01,  8.1843e-02, -3.3031e-03],\n                        [ 3.6020e-02,  2.2876e-01,  2.6749e-01, -1.5000e-02, -4.1693e-02],\n                        [ 2.0004e-01,  2.6958e-01, -1.4744e-02,  8.8433e-02,  3.9742e-02],\n                        [ 7.8550e-02,  2.8222e-02,  1.0640e-01,  2.3130e-01,  1.6952e-01]],\n              \n                       [[-6.8087e-02,  6.1967e-02,  7.0944e-03,  3.2063e-02,  1.0086e-01],\n                        [-7.1327e-03, -9.4184e-02, -1.8338e-02,  8.5798e-02,  5.2615e-02],\n                        [-7.8484e-02, -1.1016e-01,  1.1484e-01, -3.3732e-03,  4.8071e-02],\n                        [ 2.3488e-02,  1.7074e-01,  2.0093e-01,  8.6418e-02,  4.1808e-02],\n                        [-1.6087e-01,  2.0269e-02, -3.8869e-02, -3.9585e-02, -1.4548e-01]],\n              \n                       [[ 3.0513e-01,  1.5963e-01,  3.3822e-02,  7.0363e-02, -6.1679e-02],\n                        [ 5.5721e-02, -1.4452e-01, -3.3964e-02, -3.5218e-02, -4.1814e-02],\n                        [ 6.5342e-03, -2.2612e-01, -2.6323e-01, -5.2758e-02,  1.9976e-02],\n                        [-2.3883e-02, -1.3430e-01, -1.0767e-02, -3.5456e-02, -2.0816e-02],\n                        [-6.8873e-02, -1.9957e-03,  7.3153e-02, -2.8410e-02, -2.3431e-02]],\n              \n                       [[ 3.8482e-02, -1.0985e-01, -1.9099e-01, -1.3084e-01, -8.2921e-02],\n                        [-1.1516e-02, -9.9579e-02, -1.7801e-01, -8.4910e-02,  1.7735e-02],\n                        [ 4.4324e-02,  1.5527e-01,  7.2862e-02,  1.6588e-02,  9.6356e-02],\n                        [ 3.1638e-01,  2.2805e-01,  1.3923e-01,  1.3929e-03,  1.3203e-01],\n                        [-1.8280e-02, -1.9089e-01, -1.3564e-01,  4.3865e-03, -8.7615e-02]],\n              \n                       [[-2.1995e-03, -5.7430e-02, -5.3500e-02, -7.3538e-03, -4.1160e-02],\n                        [-7.5264e-02,  5.7102e-02, -5.9256e-02, -3.1364e-02,  1.2098e-01],\n                        [-3.6530e-02, -8.8949e-02, -6.8147e-02, -1.9564e-02, -8.6424e-02],\n                        [-1.0282e-01, -4.3737e-02, -3.0278e-02,  5.1790e-02, -9.0137e-02],\n                        [ 9.5290e-04, -1.7990e-02, -3.2635e-02,  8.8804e-02, -2.3491e-02]],\n              \n                       [[-4.3061e-02,  1.4893e-01, -1.7778e-03, -3.4502e-02,  2.8988e-02],\n                        [-5.7609e-02, -2.9947e-02,  1.1005e-01,  1.5290e-01,  6.5615e-02],\n                        [-1.3583e-01,  1.7645e-01,  1.7626e-01,  1.4175e-01,  9.8624e-02],\n                        [-1.4791e-01,  4.3052e-02,  3.0895e-02,  8.0589e-02,  4.7759e-02],\n                        [-2.6414e-01, -9.3287e-02, -4.3084e-02, -3.3495e-02,  2.0490e-02]]]])),\n             ('conv2.bias',\n              tensor([-0.1993, -0.5965,  0.1975,  0.0586, -0.1741,  0.4926,  0.6307,  0.0305,\n                       0.1756,  0.0762,  0.0481,  0.4004,  0.5975,  0.0976,  0.1529, -0.7603])),\n             ('fc1.weight',\n              tensor([[-0.0059, -0.0030,  0.0049,  ..., -0.0532, -0.0678, -0.0666],\n                      [-0.0330,  0.0198, -0.0210,  ...,  0.0095,  0.0284, -0.0125],\n                      [-0.0026, -0.0148,  0.0415,  ..., -0.0123, -0.0069, -0.0462],\n                      ...,\n                      [ 0.0217,  0.0607, -0.0319,  ..., -0.0750,  0.0239,  0.0327],\n                      [-0.0332,  0.0033,  0.0858,  ..., -0.0634, -0.0415, -0.1395],\n                      [ 0.0390,  0.0321,  0.0744,  ..., -0.0859, -0.0818,  0.0022]])),\n             ('fc1.bias',\n              tensor([-3.0450e-03,  4.0629e-02,  4.8400e-02, -3.7541e-02, -2.6964e-02,\n                      -3.5395e-02, -1.7923e-01,  1.5024e-01,  3.7483e-02, -5.2221e-02,\n                       4.1760e-02,  7.1957e-02,  5.2798e-02,  1.2247e-01,  2.1924e-02,\n                      -6.1512e-02, -1.8182e-01,  1.1774e-01, -2.1740e-02,  2.5802e-02,\n                       4.6696e-03,  7.4297e-02, -2.7776e-02, -5.0727e-02,  3.2858e-02,\n                      -3.5127e-02,  1.1536e-01, -6.3725e-02,  1.8885e-02,  1.9582e-01,\n                      -1.0387e-01, -7.3445e-02,  4.3242e-02, -4.2848e-02,  5.7086e-03,\n                       9.1493e-02, -8.2702e-03, -3.9109e-02,  6.0324e-02,  9.7778e-02,\n                       1.6561e-03, -9.4607e-03, -5.0242e-02,  5.0815e-03,  7.9711e-02,\n                       2.4688e-01,  1.7225e-02, -3.3209e-02,  1.1283e-01, -3.3205e-02,\n                      -3.4133e-02,  1.0902e-02, -6.1698e-02,  1.9856e-02,  5.8451e-02,\n                       1.4800e-02,  9.8677e-02,  6.7240e-02, -4.6788e-02,  1.0461e-01,\n                      -2.2049e-01, -6.0630e-05,  5.3468e-02,  1.9564e-03,  3.0488e-03,\n                       8.5137e-04, -1.3806e-01,  4.3718e-02,  1.2866e-01,  2.7256e-02,\n                       2.1787e-01,  5.8906e-02, -1.4132e-01, -9.6732e-02,  5.5545e-02,\n                       1.0815e-01,  1.3432e-01, -6.1945e-02, -1.0153e-01, -4.0959e-02,\n                       5.5847e-02, -2.5151e-02,  6.5338e-02,  9.0164e-03,  3.0928e-01,\n                       9.5516e-02,  1.9665e-01,  1.0026e-01, -7.9547e-03, -5.0350e-02,\n                      -3.6104e-02, -2.9898e-02, -2.0094e-02, -7.0471e-02,  2.5711e-02,\n                      -5.5248e-02,  1.2567e-01, -3.4213e-02,  6.5752e-02,  2.3896e-01,\n                      -8.0775e-02,  1.0485e-01,  4.8298e-02, -3.0378e-02,  1.4238e-01,\n                      -3.2611e-02,  1.4808e-01,  5.2729e-02, -3.7808e-03, -5.1753e-02,\n                       1.6785e-02, -3.1943e-02,  8.5848e-02,  5.3533e-02,  1.3250e-01,\n                       3.6309e-02,  1.0242e-01, -4.9196e-02,  1.9264e-02,  1.6591e-01])),\n             ('fc2.weight',\n              tensor([[ 0.0263, -0.0846,  0.0718,  ..., -0.0300,  0.0746,  0.0956],\n                      [-0.0535,  0.0426, -0.0427,  ..., -0.0072, -0.0333, -0.0650],\n                      [ 0.0450, -0.0069, -0.0532,  ..., -0.1172, -0.0066, -0.0440],\n                      ...,\n                      [-0.0488, -0.0118, -0.0618,  ..., -0.0423,  0.1346,  0.0143],\n                      [-0.0026,  0.1032, -0.0597,  ..., -0.0044, -0.0160, -0.0523],\n                      [ 0.0339,  0.0174,  0.1265,  ...,  0.0644, -0.0031, -0.0291]])),\n             ('fc2.bias',\n              tensor([ 0.0656, -0.0737, -0.0488,  0.1793,  0.0103,  0.0277,  0.2113,  0.0903,\n                       0.0424,  0.2083,  0.0047, -0.0343,  0.0389,  0.3767,  0.3348, -0.0122,\n                       0.0232,  0.0238,  0.1744,  0.0007,  0.0191, -0.1223, -0.0413,  0.3756,\n                      -0.1065, -0.0659,  0.0915, -0.0951, -0.0743,  0.0435,  0.0449,  0.1591,\n                       0.1982, -0.0969, -0.0529,  0.0674,  0.2052, -0.0671, -0.0182, -0.0767,\n                       0.1865,  0.0339, -0.0658,  0.1689, -0.0587,  0.0514, -0.0650, -0.0101,\n                       0.0659,  0.0236, -0.1287, -0.0205,  0.1050,  0.0686,  0.3610,  0.2138,\n                      -0.1004, -0.0891, -0.0757,  0.0542, -0.1542,  0.3569,  0.2200,  0.0981,\n                       0.0411, -0.0759, -0.0461,  0.2035,  0.4442, -0.0778, -0.0745,  0.0723,\n                       0.0541, -0.0299, -0.1749, -0.0441, -0.0720,  0.1305, -0.1414,  0.2637,\n                       0.0870, -0.0898, -0.0322,  0.0809])),\n             ('fc3.weight',\n              tensor([[ 9.8271e-02,  6.2041e-02,  7.3654e-03,  6.7684e-03, -4.2761e-02,\n                       -7.5634e-02,  1.2214e-01, -2.4669e-01,  2.1681e-01,  5.8546e-03,\n                        9.7396e-02, -3.7432e-05, -8.5343e-02, -1.3902e-01, -2.6962e-01,\n                       -8.8244e-03,  5.7324e-02,  1.2059e-01,  2.9251e-02,  1.9823e-01,\n                       -1.7474e-01,  8.1853e-02,  7.0175e-02, -2.6716e-01, -6.0597e-02,\n                       -5.0819e-02, -4.6012e-02, -1.1673e-01, -4.3314e-03, -1.6627e-01,\n                        9.1240e-02, -2.5549e-01, -8.5239e-03,  2.6625e-02,  1.0408e-01,\n                        2.5513e-02, -7.2556e-02, -2.1017e-03,  8.2921e-02, -2.8158e-02,\n                        1.3827e-01, -1.4108e-01,  1.6713e-01,  8.4509e-02, -2.2500e-02,\n                        1.6438e-01,  5.7465e-02,  1.8034e-01, -4.5847e-02,  2.9126e-01,\n                        5.8484e-02, -2.2049e-01,  1.1694e-01, -7.8672e-03, -2.8711e-01,\n                        3.3963e-01,  5.6705e-02, -8.7616e-02,  1.1167e-02,  3.5199e-02,\n                        4.7403e-02,  1.8887e-01, -6.8438e-02, -1.2628e-01, -3.2747e-02,\n                       -6.3584e-02,  6.3919e-02, -4.5173e-03, -1.9039e-01, -1.1821e-01,\n                       -8.4778e-02,  4.4096e-02,  2.3155e-01, -8.5404e-03,  3.0149e-01,\n                       -9.0256e-02, -5.1139e-02,  1.7906e-01, -2.9320e-02,  6.9404e-02,\n                        2.6587e-01,  2.5938e-02,  1.7365e-01,  1.3298e-02],\n                      [-1.4603e-01, -1.4792e-02, -1.6979e-01,  1.6521e-01,  1.8107e-01,\n                       -1.5081e-01, -7.4085e-02, -1.0930e-01, -6.0220e-02,  1.1728e-01,\n                        1.9027e-01, -5.7236e-02,  3.6662e-02, -1.4155e-01, -6.6167e-02,\n                        1.8830e-01, -6.6110e-02,  8.0598e-02,  4.2703e-02, -2.3265e-01,\n                        7.2014e-02, -2.6561e-02, -2.2536e-02, -1.2088e-02,  3.5408e-01,\n                        2.4514e-01, -3.4417e-01,  3.1332e-01,  7.4690e-03, -1.8511e-01,\n                        1.8852e-02, -1.8763e-02,  6.9964e-02,  1.6426e-01, -8.3177e-02,\n                       -3.8577e-02,  2.7799e-02, -2.0152e-01,  9.3537e-04,  9.9626e-02,\n                       -1.0277e-01,  4.7260e-02,  1.0458e-01, -1.1523e-01,  3.4936e-02,\n                        6.0824e-02,  9.3407e-02,  6.2722e-02, -1.9497e-01, -5.4880e-02,\n                        1.0605e-01,  7.3924e-02,  1.8362e-02, -4.8670e-02, -3.1833e-01,\n                        1.4846e-01,  3.3926e-02, -5.8603e-02,  4.9137e-02, -2.5960e-02,\n                        2.5029e-01, -2.9334e-01, -1.6861e-01,  1.0896e-01,  9.9372e-02,\n                       -3.8029e-02, -8.2852e-02, -3.2467e-01, -1.9625e-01,  1.6111e-01,\n                        1.3369e-01, -6.8727e-02,  5.3057e-03, -4.3172e-02,  2.6190e-01,\n                       -8.2799e-02,  4.6634e-02, -2.0829e-02,  4.2512e-02, -2.5459e-01,\n                        1.4167e-01,  8.9601e-02, -1.3400e-02,  8.4188e-02],\n                      [-1.2099e-01, -6.4472e-02,  2.1580e-01,  8.5086e-02, -4.2245e-04,\n                       -1.2814e-01, -8.6865e-02, -2.4134e-02,  7.0592e-02,  1.8725e-01,\n                       -1.3809e-01, -4.7481e-02,  2.3178e-02, -3.5854e-02,  5.6988e-02,\n                       -5.3015e-02, -6.0831e-02,  4.1776e-02,  2.9084e-01,  2.2129e-01,\n                       -7.9801e-03, -6.5509e-02, -2.2578e-02,  2.1657e-03, -6.7803e-02,\n                       -3.1673e-02, -9.1475e-02, -1.7315e-02,  1.1737e-01, -8.7606e-02,\n                       -4.8442e-02,  1.5214e-01,  1.8766e-01, -1.2365e-01,  9.4750e-02,\n                       -1.1109e-01,  1.0241e-01,  2.3259e-02,  1.0010e-01,  6.3986e-02,\n                        5.2223e-02, -1.4340e-01, -5.2498e-02, -5.6067e-02,  2.5768e-04,\n                       -9.7353e-03, -7.4522e-02, -4.7736e-02,  4.1305e-02,  1.0062e-01,\n                       -6.9159e-02,  5.4602e-02,  1.1992e-01,  1.1220e-01,  9.7207e-02,\n                        9.6095e-02,  1.6609e-02,  2.9140e-02, -1.1148e-01, -4.2008e-02,\n                       -7.5521e-02,  3.2866e-01,  3.0078e-01, -6.6110e-02, -6.5939e-02,\n                        6.6593e-02,  5.8532e-02,  2.3939e-01,  1.7807e-01, -4.0331e-02,\n                        1.2726e-01, -1.1658e-01, -1.0609e-01, -5.5100e-02, -3.2387e-01,\n                        5.6984e-02, -2.6812e-02,  1.6472e-01, -9.5942e-02,  9.9533e-02,\n                       -1.3428e-01, -1.3866e-01,  2.5625e-02,  2.1592e-02],\n                      [ 6.3974e-02, -4.3815e-02, -1.1730e-01, -2.1852e-01, -1.7560e-01,\n                        1.9738e-01, -2.5618e-02,  1.2935e-01,  7.2991e-02, -5.4458e-02,\n                       -1.7681e-01, -3.4023e-04,  3.4684e-02, -1.3984e-02,  1.6829e-01,\n                       -1.5197e-02,  1.0141e-01,  7.2433e-03,  6.2465e-02, -4.3463e-02,\n                       -1.5077e-01, -1.0905e-01,  3.8990e-02,  2.2907e-01, -1.1884e-01,\n                        1.0931e-01,  2.3254e-01, -7.8050e-02,  2.1223e-02, -2.2133e-02,\n                        6.4121e-02,  4.1896e-02,  1.0452e-01, -6.2980e-02, -6.8751e-02,\n                       -2.3919e-02, -1.4939e-01,  2.5464e-03,  2.8458e-02, -2.3502e-02,\n                       -1.2360e-01,  9.8130e-02, -4.0717e-02,  4.7174e-02,  9.5771e-02,\n                        1.1611e-01, -3.9433e-02,  3.9794e-02,  3.6247e-02, -1.1682e-01,\n                       -9.5780e-02, -2.1350e-02,  8.8867e-02, -6.3591e-03,  2.1556e-01,\n                       -2.3197e-01,  8.5764e-02,  1.0294e-01,  9.8460e-02, -3.9878e-02,\n                       -4.0205e-02, -6.6334e-02,  1.0153e-01,  1.8447e-01,  9.9783e-02,\n                       -8.0762e-02,  7.1190e-02,  8.6246e-02, -3.3568e-02, -1.6085e-01,\n                        2.6641e-02, -8.3632e-02, -2.7196e-02, -5.2815e-02, -1.5037e-01,\n                        2.1188e-02, -9.9052e-02,  7.7930e-04, -6.2345e-02,  9.5551e-02,\n                       -1.9791e-01, -2.1970e-01,  6.5375e-02,  7.0038e-02],\n                      [-1.9625e-01,  8.6634e-02, -1.7867e-01,  7.6490e-02, -3.9791e-02,\n                       -1.1055e-01, -2.4022e-01,  7.8865e-02,  5.9925e-02,  2.8823e-02,\n                        5.1420e-02,  5.3804e-02,  8.9741e-02,  2.0435e-01,  1.6218e-01,\n                        5.1336e-02,  4.4030e-02, -1.0887e-01,  1.5904e-01,  4.4105e-02,\n                        2.2035e-01, -7.6110e-02,  2.5257e-02,  1.4832e-02, -1.3589e-01,\n                       -6.7994e-02, -1.6284e-02, -1.6591e-01,  3.5815e-02,  8.5912e-03,\n                       -1.0756e-01,  1.7930e-01,  1.4646e-01,  2.5785e-01, -1.7119e-01,\n                       -7.9585e-02,  1.4883e-01, -1.4539e-01,  4.3039e-02,  4.5167e-02,\n                        1.7249e-01, -1.5598e-01,  4.5862e-02,  1.6832e-01,  3.8424e-02,\n                       -2.1934e-01, -7.5124e-02,  8.1994e-02,  1.6492e-01, -1.2510e-01,\n                        4.0692e-02, -2.0001e-01, -1.2040e-01, -1.2339e-01,  3.2136e-01,\n                        1.3469e-02, -4.0840e-02,  4.2631e-02, -7.3196e-02, -2.0403e-02,\n                       -2.9171e-01,  2.4037e-01, -1.9836e-01, -9.8742e-02, -1.7844e-01,\n                        6.9171e-02,  3.3862e-02,  6.6759e-02,  3.3049e-01, -1.0359e-02,\n                       -1.5950e-02, -3.5083e-02, -6.5824e-02,  4.4525e-02, -5.2465e-02,\n                        1.9396e-02,  1.1057e-01,  7.9949e-02,  1.2559e-02,  1.3284e-01,\n                       -1.2662e-02,  6.5302e-02, -2.3250e-01, -1.8236e-01],\n                      [ 2.3543e-01, -6.5305e-02,  1.9154e-01, -1.4862e-01, -1.1169e-02,\n                        2.0703e-01, -1.3363e-01,  3.5074e-01,  7.4601e-02,  4.5992e-02,\n                       -7.9723e-02,  6.6599e-02,  2.4181e-02, -2.5399e-02,  1.9227e-01,\n                       -1.9299e-01,  1.0471e-01, -3.6628e-02,  8.1987e-02,  2.4731e-02,\n                        1.0714e-01, -7.5896e-02,  5.0941e-02,  2.4725e-02, -3.8884e-02,\n                        6.3556e-02,  2.3785e-01, -7.9836e-02, -1.1003e-01, -1.6016e-02,\n                        2.0609e-02,  9.3085e-02,  2.1413e-01, -6.2665e-02, -6.3687e-02,\n                       -5.9215e-02, -2.1529e-01,  1.0430e-01, -2.8628e-02, -6.2850e-02,\n                       -1.6671e-01,  1.7029e-01, -1.4540e-02,  3.3009e-02,  1.2428e-05,\n                       -1.8397e-02,  8.5760e-02,  4.1876e-02,  5.3374e-02,  6.5548e-02,\n                       -2.3417e-01,  1.4787e-01,  2.8475e-02, -8.8476e-03,  1.5772e-01,\n                       -3.1072e-01,  6.6157e-02,  2.8689e-02, -4.5600e-02, -6.3191e-02,\n                       -2.6167e-01, -1.2077e-01,  3.8559e-02,  6.2389e-02,  6.1623e-02,\n                       -1.2258e-01, -3.5445e-02,  1.1921e-01,  2.5725e-02, -1.4635e-01,\n                        1.1415e-01,  8.1280e-02, -1.0883e-01, -4.4081e-02, -1.1515e-01,\n                        2.5044e-03, -9.5257e-02, -7.5313e-02,  1.0560e-02, -7.7689e-02,\n                       -2.4668e-01, -1.9717e-01, -4.0816e-03, -7.6254e-02],\n                      [-1.8476e-01,  5.5188e-02, -1.9228e-01,  2.4044e-01,  8.3047e-02,\n                        2.0752e-03,  7.7902e-02, -2.0857e-02, -3.4691e-02,  2.8993e-01,\n                       -4.7938e-02, -4.2690e-02,  8.6384e-02,  3.5935e-01,  2.0043e-01,\n                       -1.3671e-01,  8.3997e-02, -8.3311e-02, -6.8133e-02, -1.2301e-01,\n                       -8.8138e-02, -1.3594e-01, -4.0118e-02,  3.9329e-01, -1.8541e-01,\n                        4.7496e-02, -2.4928e-02, -4.7554e-02, -2.8273e-02, -1.3465e-01,\n                        1.0448e-01,  1.3334e-01,  9.8372e-02, -5.7720e-02, -4.4438e-02,\n                       -5.2349e-03,  2.5412e-02, -1.3431e-01, -1.0768e-01, -8.8567e-03,\n                        1.8256e-01,  1.7630e-01,  5.7174e-02, -5.9675e-02, -1.0278e-01,\n                        2.5084e-01, -2.1003e-02, -1.7447e-01, -1.2801e-01,  3.7547e-02,\n                       -1.9811e-01,  6.0456e-02, -6.6665e-02,  1.2761e-01,  4.2012e-02,\n                       -2.8359e-01, -1.0607e-01,  9.5192e-02,  8.4674e-02,  5.4042e-02,\n                       -2.5546e-01, -6.9244e-02,  3.2979e-01, -1.6853e-01, -9.1829e-02,\n                       -7.9324e-02, -8.9985e-03, -1.7645e-01,  3.0001e-01, -1.7428e-01,\n                        9.1442e-02, -4.3163e-02, -1.6075e-02, -3.7066e-02,  1.6097e-02,\n                        1.7112e-02, -4.1602e-02, -9.0785e-02, -1.1520e-01, -6.4970e-02,\n                       -1.7601e-01, -1.7870e-01,  1.2769e-01, -9.6560e-03],\n                      [-8.9233e-03, -7.2689e-02,  1.6515e-01, -2.6256e-01, -1.7741e-01,\n                       -7.6770e-02, -9.8954e-02,  1.7109e-01, -7.9970e-02,  1.1947e-02,\n                       -8.7886e-02,  7.1083e-02, -1.2996e-01, -9.9127e-02, -1.4498e-01,\n                       -1.0690e-01,  1.1009e-01,  8.1052e-02, -1.7750e-01,  1.3679e-01,\n                        1.4024e-01,  1.6637e-01, -7.4334e-02, -6.7875e-02, -2.0112e-01,\n                       -3.6521e-02,  2.8117e-01, -2.3060e-01,  5.5009e-02, -2.0851e-02,\n                        3.4891e-02,  2.0817e-01, -1.1281e-01,  1.8377e-01, -1.3437e-01,\n                       -4.6792e-03, -1.5217e-01,  8.3508e-02,  8.6020e-02,  9.2768e-02,\n                       -1.5026e-01, -5.7353e-02,  1.4981e-02, -6.7857e-02, -3.5924e-03,\n                       -1.8132e-01,  8.0216e-02, -2.8099e-02,  2.7318e-01,  7.6384e-03,\n                       -1.1348e-01,  1.2016e-01,  1.2157e-02,  8.7784e-02,  1.5938e-01,\n                       -1.9147e-01,  2.5213e-02, -1.8063e-02,  7.7707e-02, -7.9625e-02,\n                        5.3096e-02, -1.2587e-01, -1.4181e-01, -1.0830e-01,  1.2953e-02,\n                        9.3912e-02,  1.0946e-01,  7.8688e-02,  3.1027e-01,  2.1737e-01,\n                        5.2797e-02,  1.5043e-01, -9.5451e-02,  8.3263e-02,  1.3882e-02,\n                        3.1294e-02, -6.5951e-02, -2.1868e-01,  3.2220e-01, -1.3968e-01,\n                       -2.0129e-01,  2.0999e-01, -4.4173e-02, -2.8654e-02],\n                      [ 2.1737e-01,  1.0699e-01, -1.6911e-01,  1.9924e-02,  3.0671e-02,\n                        3.4741e-02,  3.1915e-01, -7.1881e-02, -1.5469e-01, -2.9375e-02,\n                        1.2537e-01,  5.2278e-02,  4.1077e-02, -2.2408e-01, -1.8877e-01,\n                       -2.9288e-02,  1.5911e-02,  5.2837e-02, -1.1627e-01, -1.2426e-01,\n                       -6.7418e-02,  3.2086e-02,  4.4862e-02, -2.3060e-01,  1.9155e-01,\n                       -2.5092e-01, -1.7655e-01,  1.2261e-01, -4.3522e-02,  2.7957e-01,\n                       -8.3041e-02, -2.6728e-01, -1.4774e-01, -2.9143e-01,  3.6105e-02,\n                        1.0798e-02,  1.8373e-01, -8.3488e-02, -1.6638e-03, -5.9490e-02,\n                       -9.3993e-02, -1.0469e-01, -1.3327e-02, -9.4313e-02, -5.7407e-02,\n                       -4.1263e-02,  1.6427e-01, -1.5078e-02, -2.4731e-01,  3.8506e-02,\n                       -1.3469e-01, -2.6656e-01, -3.3308e-02, -8.3415e-02, -2.8753e-01,\n                        3.4085e-01,  8.4379e-02, -1.0440e-01, -5.0212e-02,  3.7600e-02,\n                        1.2644e-01, -3.0174e-02, -9.1134e-02,  1.2755e-01,  1.0052e-01,\n                       -9.1161e-02, -6.6172e-02,  7.2463e-03, -4.4019e-01,  2.9283e-03,\n                       -1.1654e-01, -2.9528e-02,  3.0580e-01, -9.3530e-02, -9.7699e-02,\n                       -8.3806e-02, -2.5697e-02,  1.9852e-01,  6.4260e-02,  2.2936e-01,\n                        3.2726e-01, -7.3355e-02, -8.4751e-02,  2.3993e-01],\n                      [-7.7060e-02, -8.0583e-02, -8.1425e-02,  9.1598e-03,  2.0257e-01,\n                       -1.6506e-01, -7.0434e-02, -1.3322e-01,  7.3352e-02, -1.2147e-01,\n                        2.4229e-02,  7.5184e-02, -9.2786e-02, -2.8743e-02, -2.3141e-01,\n                        2.6256e-02,  2.1022e-02,  1.9445e-01, -1.9953e-01, -3.5909e-02,\n                       -1.2299e-01,  1.1029e-01,  9.8098e-02, -1.1042e-01,  1.8326e-01,\n                        5.9445e-02, -1.4752e-01,  1.9963e-01,  9.5044e-02,  2.1076e-01,\n                        5.9174e-02, -1.2818e-01, -2.5021e-02,  7.7679e-02, -7.8637e-02,\n                       -7.1951e-02,  2.0745e-03,  2.1810e-01,  9.1392e-02,  1.1028e-01,\n                       -8.4260e-02,  2.5014e-01, -1.5127e-01, -3.3841e-02,  9.8379e-02,\n                       -4.4623e-02,  1.4693e-01, -1.1188e-01, -7.3162e-02, -1.2597e-01,\n                        3.4069e-01,  1.2050e-01, -1.4013e-01,  1.1088e-02, -1.9753e-01,\n                        1.2157e-01,  5.1204e-03, -2.3080e-02,  6.4612e-03, -4.1885e-02,\n                        3.7831e-01, -2.8248e-01, -2.1803e-02, -2.1584e-02, -8.5224e-02,\n                       -1.3964e-02,  8.5107e-02, -1.3381e-01, -2.4500e-01, -1.0169e-01,\n                        5.2115e-02,  5.6954e-02,  2.6710e-01, -5.5491e-02,  1.9357e-01,\n                        5.1620e-02,  9.4148e-02, -2.6390e-02, -7.1705e-02, -9.0073e-02,\n                        4.9448e-02,  6.0975e-02,  1.2613e-02,  9.9296e-03]])),\n             ('fc3.bias',\n              tensor([-0.1099, -0.7215,  0.3368,  0.5183,  0.3644, -0.0155,  0.1354, -0.2825,\n                       0.2242, -0.2805]))])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './cifar_net.pth'        # -> run import cell and this cell to grab trained model\n",
    "torch.load(PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:50:31.479390Z",
     "start_time": "2023-11-03T14:50:31.386301800Z"
    }
   },
   "id": "7fe68444bcefc10a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:50:31.485395200Z",
     "start_time": "2023-11-03T14:50:31.433347500Z"
    }
   },
   "id": "da58dfc3b1396ea6"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:50:31.485395200Z",
     "start_time": "2023-11-03T14:50:31.451364500Z"
    }
   },
   "id": "f1891d0847e5d770"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:50:31.486396100Z",
     "start_time": "2023-11-03T14:50:31.466377800Z"
    }
   },
   "id": "83ff574753da62b0"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:50:31.511419600Z",
     "start_time": "2023-11-03T14:50:31.480392200Z"
    }
   },
   "id": "21f616a58ae35533"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T14:50:31.522428300Z",
     "start_time": "2023-11-03T14:50:31.498407400Z"
    }
   },
   "id": "495b51d4dc290e7f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
